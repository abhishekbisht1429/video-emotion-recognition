{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "hostname = os.popen(\"hostname\").read().split(\"\\n\")[0]\n",
    "if(hostname != \"reckoner1429-Predator-PH315-52\" and hostname != \"jarvis\"):\n",
    "    from google.colab import drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "\n",
    "    ! chmod 755 \"/content/gdrive/My Drive/collab-var.sh\"\n",
    "    ! \"/content/gdrive/My Drive/collab-var.sh\"\n",
    "    %cd \"/content/gdrive/My Drive/github/video-emotion-recognition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import utils.data_util as data_util\n",
    "import utils.preprocess_util as preprocess_util\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, Flatten, Concatenate\n",
    "from tensorflow.keras import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras as keras\n",
    "import time\n",
    "import utils.config as config\n",
    "from utils.hyparam_util import load_fusion_hyparam\n",
    "import sklearn.metrics as skm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if(config.CURRENT_DATASET == 'SAVEE'):\n",
    "#     dataset = preprocess_util.SAVEE()\n",
    "# elif(config.CURRENT_DATASET == 'RAVDESS'):\n",
    "#     dataset = preprocess_util.RAVDESS()\n",
    "dataset = preprocess_util.RML()\n",
    "SEED = 0 \n",
    "X_train_audio, X_test_audio, Y_train_audio, Y_test_audio = dataset.load_audio_filenames(SEED, 0.2)\n",
    "X_train_face, X_test_face, Y_train_face, Y_test_face = dataset.load_visual_filenames(SEED, 0.2)\n",
    "print(X_test_audio)\n",
    "print(Y_test_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "iteration = \"A3\"\n",
    "path = os.path.join(dataset.MODEL_SAVE_DIR, \"iteration-\"+iteration)\n",
    "new_model = tf.keras.models.load_model(path +'/saved_models/xception-8-8-8-A3.h5')\n",
    "\n",
    "#new_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_WIDTH = 224\n",
    "INPUT_HEIGHT = 224\n",
    "hyparams = load_fusion_hyparam(iteration)\n",
    "BATCH_SIZE = hyparams['batch_size']\n",
    "N_CLASSES = len(dataset.emotion_classes)\n",
    "epochs = hyparams['epochs']\n",
    "# ITERATION = hyparams['iteration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_gen = data_util.MultimodalDataGenerator(X_test_face, X_test_audio, Y_test_face, BATCH_SIZE, INPUT_WIDTH, INPUT_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = new_model.predict(X_val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "print(type(pred))\n",
    "print(pred.shape)\n",
    "print(Y_test_face.shape)\n",
    "\n",
    "EMOTION_CLASSES = dataset.emotion_classes\n",
    "\n",
    "true_values = []\n",
    "pred_values = []\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    true_values.append(EMOTION_CLASSES[np.argmax(Y_test_face[i])])\n",
    "    pred_values.append(EMOTION_CLASSES[np.argmax(pred[i])])\n",
    "    \n",
    "print(true_values)\n",
    "print(pred_values)\n",
    "            \n",
    "\n",
    "cm = skm.confusion_matrix(true_values, pred_values, labels = EMOTION_CLASSES)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the densenet121\\n')\n",
    "c=fig.colorbar(cax)\n",
    "# c.add_lines(CS, erase=True)\n",
    "#ax.set_xticklabels([' '] + EMOTION_CLASSES)\n",
    "#ax.set_yticklabels([' '] + EMOTION_CLASSES)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#Histories\n",
    "path = dataset.MODEL_SAVE_DIR\n",
    "path_fusion = path + '/iteration-A3/history'\n",
    "path_ftm = path + '/ftm-0/history'\n",
    "# print(path_ftm)\n",
    "# print(path_fusion)\n",
    "model_histories = {}\n",
    "\n",
    "for model_history in os.listdir(path_fusion):\n",
    "    model_history_path = path_fusion + '/' + model_history\n",
    "    if(os.path.isfile(model_history_path)):\n",
    "        model_histories[model_history.split('.')[0]] = np.load(model_history_path, allow_pickle = True)\n",
    "        print(model_history)\n",
    "#print(\"=======================================================================================\")\n",
    "        \n",
    "for model_history in os.listdir(path_ftm):\n",
    "    model_history_path = path_ftm + '/' + model_history\n",
    "    if(os.path.isfile(model_history_path)):\n",
    "        model_histories[model_history.split('.')[0]] = np.load(model_history_path, allow_pickle = True)\n",
    "        print(model_history)\n",
    "#print(\"=======================================================================================\")\n",
    "\n",
    "#change model name here to check history\n",
    "model_name = \"densenet121\"\n",
    "key_fusion = model_name + \"-8-8-8-A3-history\"\n",
    "key_face = \"ftm-\" + model_name + \"-face-8-history\"\n",
    "key_audio = \"ftm-\" + model_name + \"-audio-8-history\"\n",
    "\n",
    "print(model_histories[key_face])\n",
    "print(\"=======================================================================================\")\n",
    "\n",
    "print(model_histories[key_audio])\n",
    "print(\"=======================================================================================\")\n",
    "\n",
    "print(model_histories[key_fusion])\n",
    "print(\"=======================================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.2 64-bit",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}